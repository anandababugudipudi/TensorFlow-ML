{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Core Learning Algos_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/H0QnPsRBU1ivo5krnt+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandababugudipudi/TensorFlow-ML/blob/main/3_Core_Learning_Algos_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bS6KTNGWWht"
      },
      "source": [
        "**Classificatin Problem on IRIS Flower Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySzxqid2pmkg"
      },
      "source": [
        "# Importing the necessary modules\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOxfr3-TqErs"
      },
      "source": [
        "**IRIS Flower Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qU3V6GqACa"
      },
      "source": [
        "# Features and Labels\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "# Load dataset.\n",
        "XTrain = pd.read_csv(\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\", names = CSV_COLUMN_NAMES, header = 0)\n",
        "XTest = pd.read_csv(\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\", names = CSV_COLUMN_NAMES, header = 0)\n",
        "print(XTrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvzs8b_pVU72"
      },
      "source": [
        "XTrain.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo2-WtDTXPMQ"
      },
      "source": [
        "# Loading the Labels\n",
        "yTrain = XTrain.pop('Species')\n",
        "yTest = XTest.pop('Species')\n",
        "print(yTrain.shape)\n",
        "print(yTest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeGlg0F6XS8W"
      },
      "source": [
        "# Creating an input function\n",
        "def input_fn(features, labels, training = True, batch_size = 256):\n",
        "  # Covnert the inputs into a Dataset\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  if training:\n",
        "    ds = ds.shuffle(1000).repeat()\n",
        "  return ds.batch(batch_size)\n",
        "\n",
        "# Creating feature columns\n",
        "feature_columns = []\n",
        "for key in XTrain.keys():\n",
        "  feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
        "print(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMsrwrcNYHLf"
      },
      "source": [
        "# Building the classifier model\n",
        "# Here we are building a Deep Neural Network Classifier with 30 and 10 hidden nodes eachother\n",
        "# We will be using n_classes = 3 as we have to classify among 3 classes\n",
        "model = tf.estimator.DNNClassifier(\n",
        "    feature_columns = feature_columns,\n",
        "    hidden_units = [30, 10], \n",
        "    n_classes = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVuxMKx7YsXC"
      },
      "source": [
        "# Training the model\n",
        "model.train(\n",
        "    input_fn = lambda : input_fn(XTrain, yTrain, training = True),\n",
        "    steps = 7000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f7SZTS4a8dh"
      },
      "source": [
        "# Evaluating the model\n",
        "eval_results = model.evaluate(\n",
        "    input_fn = lambda : input_fn(XTest, yTest, training = False))\n",
        "clear_output()\n",
        "print(f\"The accuracy is {round(eval_results['accuracy']*100,2)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af-LxCfpceFp"
      },
      "source": [
        "# Predicting the model with user inputs\n",
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "predict = {}\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "for feature in features:\n",
        "  valid = True\n",
        "  while valid: \n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict[feature] = [float(val)]\n",
        "\n",
        "predictions = model.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa4wQo95eIMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}